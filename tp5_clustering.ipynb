{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP5 : Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-02T02:13:03.699739Z",
     "start_time": "2020-12-02T02:13:02.209281Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn import datasets\n",
    "from sklearn.cluster import KMeans, DBSCAN, SpectralClustering\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples, adjusted_rand_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Version des librairies utilisées pour coder ce notebook :\n",
    "- pandas version: 1.1.4\n",
    "- numpy version: 1.19.4\n",
    "- matplotlib version: 3.3.3\n",
    "- scikit-learn version: 0.23.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-02T02:13:05.617647Z",
     "start_time": "2020-12-02T02:13:05.613829Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"pandas version:\", pd.__version__)\n",
    "print(\"numpy version:\", np.__version__)\n",
    "print(\"matplotlib version:\", matplotlib.__version__)\n",
    "print(\"scikit-learn version:\", sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans ce notebook nous allons appliquer des algorithmes de clustering à différent jeux de données. Dans un premier temps nous manipulerons ces algorithmes sur des données simulées simples, afin d'explorer leur paramètres. Nous allons ensuite introduire quelques concepts pour évaluer la qualité d'un cluster. Une dernière partie sera l'occasion de clusteriser une population de pingouins parmi trois espèces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0 - Préparation données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous utilisons **5 jeux de données** (4 simulés et 1 réel). Chacune des bases sera accessible via un dataframe qui regroupera ses features (*x1*, *x2*, etc.) ainsi que les vrais clusters (*label*) ou les clusters prédits (*cluster*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonction plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-02T02:13:12.366269Z",
     "start_time": "2020-12-02T02:13:12.359366Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_point_clouds(data, feature_x, feature_y, feature_label, \n",
    "                      title=None, legend=False, figsize=(5, 5)):\n",
    "    \"\"\"Plot point clouds.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pd.DataFrame\n",
    "        Dataframe with the point cloud values.\n",
    "    feature_x : str\n",
    "        Name of the feature to plot along the x-axis.\n",
    "    feature_y : str\n",
    "        Name of the feature to plot along the y-axis.\n",
    "    feature_label : str\n",
    "        Name of the feature to use to colorized the different clusters.\n",
    "    title : str\n",
    "        Title of the plot.\n",
    "    legend : bool\n",
    "        Display a legend or not.\n",
    "    figsize : Tuple\n",
    "        Tuple with two integers to set the plot size.\n",
    "    \n",
    "    \"\"\"\n",
    "    # get label names\n",
    "    labels = list(set(data.loc[:, feature_label]))\n",
    "    n = len(labels)\n",
    "    \n",
    "    # initialize plot\n",
    "    plt.figure(figsize=figsize)\n",
    "    \n",
    "    # scatter plot for each label\n",
    "    for i, label in enumerate(labels):\n",
    "        data_label = data.loc[data.loc[:, feature_label] == label]\n",
    "        x = data_label.loc[:, feature_x]\n",
    "        y = data_label.loc[:, feature_y]\n",
    "        if label == -1:\n",
    "            plt.scatter(x, y, s=30, color=\"black\", label=label)\n",
    "        else:\n",
    "            plt.scatter(x, y, s=30, cmap=\"Paired\", label=label)\n",
    "        \n",
    "    # format axes and legend\n",
    "    plt.xlabel(feature_x, fontweight=\"bold\", fontsize=15)\n",
    "    plt.ylabel(feature_y, fontweight=\"bold\", fontsize=15)\n",
    "    if title is not None:\n",
    "        plt.title(title, fontweight=\"bold\", fontsize=20)\n",
    "    if legend:\n",
    "        plt.legend(prop={'size': 15})\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # end plot\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Données réelles - Palmer Penguins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La base de donnée réelle que nous utilison a été originellement publiée dans :\n",
    "\n",
    "  - Gorman KB, Williams TD, Fraser WR (2014). Ecological sexual\n",
    "    dimorphism and environmental variability within a community of\n",
    "    Antarctic penguins (genus *Pygoscelis*). PLoS ONE 9(3):e90081.\n",
    "    <https://doi.org/10.1371/journal.pone.0090081>\n",
    "    \n",
    "Les données peuvent être retrouvées sur https://github.com/allisonhorst/palmerpenguins. Pour la suite du notebook nous ne gardons qu'une version simplifiée de la base de données. Cette dernière contient les mensurations et les caractéristiques d'une **population de 344 pingouins issus de 3 espèces différentes** : Chinstrap, Gentoo et Adélie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/penguins.png \"Artwork by @allison_horst\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En local vous pouvez lire les données directement depuis le fichier csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-02T02:13:14.184842Z",
     "start_time": "2020-12-02T02:13:14.160028Z"
    }
   },
   "outputs": [],
   "source": [
    "path = \"./data_penguin.csv\"\n",
    "df_penguin = pd.read_csv(path)\n",
    "print(df_penguin.shape)\n",
    "print(set(df_penguin.loc[:, \"label\"]))\n",
    "df_penguin.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En ligne sur un colab vous pouvez lire la base de données via le package dédié (après avoir utilisé la commande *!pip install palmerpenguins*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from palmerpenguins import load_penguins\n",
    "df_penguin = load_penguins()\n",
    "df_penguin.loc[:, \"label\"] = df_penguin.loc[:, \"species\"].str.lower()\n",
    "print(df_penguin.shape)\n",
    "print(set(df_penguin.loc[:, \"label\"]))\n",
    "df_penguin.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parmi les features disponibles nous avons les mensurations du bec, des palmes, le poids et le sexe.\n",
    "<img src=\"images/bill_size.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction `plot_point_clouds` permet d'afficher rapidement un nuage de point coloré en fonction du paramètre *feature_label*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-02T02:13:15.592524Z",
     "start_time": "2020-12-02T02:13:15.314263Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_point_clouds(data=df_penguin, \n",
    "                  feature_x=\"flipper_length_mm\", \n",
    "                  feature_y=\"body_mass_g\", \n",
    "                  feature_label=\"label\",\n",
    "                  title=\"Penguin mensuration\",\n",
    "                  legend=True,\n",
    "                  figsize=(8, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Données simulées"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous utilisons également 4 jeux de données simulées qui présentent des caractéristiques bien distinctes :\n",
    "- Un nuage de points non linéairement séparable en **cercles concentriques**.\n",
    "- Un nuage de points composé d'un **mélange de gaussiennes** avec des variances différentes.\n",
    "- Un nuage de point **anisotrope** (la variance va dépendre de la direction).\n",
    "- Un nuage de point suivant une loi uniforme, **sans structure sous-jacente**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-02T02:13:17.587429Z",
     "start_time": "2020-12-02T02:13:16.955261Z"
    }
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "random_state = 170\n",
    "n_samples = 1500\n",
    "\n",
    "# set random seed\n",
    "np.random.seed(random_state)\n",
    "\n",
    "### Circles ###\n",
    "noisy_circles = datasets.make_circles(n_samples=n_samples, factor=.5, noise=.05)\n",
    "df_circles = pd.DataFrame({\"x1\": noisy_circles[0][:, 0],\n",
    "                           \"x2\": noisy_circles[0][:, 1],\n",
    "                           \"label\": noisy_circles[1]})\n",
    "plot_point_clouds(data=df_circles, \n",
    "                  feature_x=\"x1\", \n",
    "                  feature_y=\"x2\", \n",
    "                  feature_label=\"label\",\n",
    "                  title=\"Circles distribution\")\n",
    "\n",
    "### Blobs distribution ###\n",
    "data, label = datasets.make_blobs(n_samples=n_samples, \n",
    "                                  cluster_std=[1.0, 2.5, 0.5], \n",
    "                                  random_state=random_state)\n",
    "df_blobs = pd.DataFrame({\"x1\": data[:, 0],\n",
    "                         \"x2\": data[:, 1],\n",
    "                         \"label\": label})\n",
    "plot_point_clouds(data=df_blobs, \n",
    "                  feature_x=\"x1\", \n",
    "                  feature_y=\"x2\", \n",
    "                  feature_label=\"label\",\n",
    "                  title=\"Gaussians distribution\")\n",
    "\n",
    "### Anisotropic distribution ###\n",
    "data, label = datasets.make_blobs(n_samples=n_samples, random_state=random_state)\n",
    "transformation = [[0.6, -0.6], [-0.4, 0.8]]\n",
    "data_aniso = np.dot(data, transformation)\n",
    "df_aniso = pd.DataFrame({\"x1\": data_aniso[:, 0],\n",
    "                         \"x2\": data_aniso[:, 1],\n",
    "                         \"label\": label})\n",
    "plot_point_clouds(data=df_aniso, \n",
    "                  feature_x=\"x1\", \n",
    "                  feature_y=\"x2\", \n",
    "                  feature_label=\"label\",\n",
    "                  title=\"Anisotropic distribution\")\n",
    "\n",
    "### Uniform distribution ###\n",
    "uniform = np.random.rand(n_samples, 2)\n",
    "label = np.zeros((n_samples,), dtype=np.int64)\n",
    "df_uniform = pd.DataFrame({\"x1\": uniform[:, 0],\n",
    "                           \"x2\": uniform[:, 1],\n",
    "                           \"label\": label})\n",
    "plot_point_clouds(data=df_uniform, \n",
    "                  feature_x=\"x1\", \n",
    "                  feature_y=\"x2\", \n",
    "                  feature_label=\"label\",\n",
    "                  title=\"Uniform distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Modèles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-mean clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'objectif de l'algorithme k-means est retrouver $K$ clusters (et leur centroïde $\\mu_k$) de manière à **minimiser la variance intra-cluster** :\n",
    "\n",
    "\\begin{align}\n",
    "V = \\sum_{k = 1}^{K} \\sum_{x \\in C_k} \\frac{1}{|C_k|} (\\|x - \\mu_k\\|^2)\n",
    "\\end{align}\n",
    "\n",
    "Documentation : https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-02T02:13:21.574288Z",
     "start_time": "2020-12-02T02:13:21.394126Z"
    }
   },
   "outputs": [],
   "source": [
    "kmean = KMeans(\n",
    "    n_clusters=3, init='k-means++', \n",
    "    n_init=10, max_iter=300, tol=0.0001, \n",
    "    verbose=0, random_state=13, \n",
    "    algorithm='auto')\n",
    "kmean.fit(df_circles.loc[:, [\"x1\", \"x2\"]])\n",
    "df_circles.loc[:, \"cluster\"] = kmean.labels_\n",
    "plot_point_clouds(data=df_circles, \n",
    "                  feature_x=\"x1\", \n",
    "                  feature_y=\"x2\", \n",
    "                  feature_label=\"cluster\",\n",
    "                  title=\"Circles distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-02T02:13:22.970980Z",
     "start_time": "2020-12-02T02:13:22.734255Z"
    }
   },
   "outputs": [],
   "source": [
    "kmean = KMeans(\n",
    "    n_clusters=3, init='k-means++', \n",
    "    n_init=10, max_iter=300, tol=0.0001, \n",
    "    verbose=0, random_state=13, \n",
    "    algorithm='auto')\n",
    "kmean.fit(df_blobs.loc[:, [\"x1\", \"x2\"]])\n",
    "df_blobs.loc[:, \"cluster\"] = kmean.labels_\n",
    "plot_point_clouds(data=df_blobs, \n",
    "                  feature_x=\"x1\", \n",
    "                  feature_y=\"x2\", \n",
    "                  feature_label=\"cluster\",\n",
    "                  title=\"Gaussians distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-02T02:13:23.568007Z",
     "start_time": "2020-12-02T02:13:23.366175Z"
    }
   },
   "outputs": [],
   "source": [
    "kmean = KMeans(\n",
    "    n_clusters=3, init='k-means++', \n",
    "    n_init=10, max_iter=300, tol=0.0001, \n",
    "    verbose=0, random_state=13, \n",
    "    algorithm='auto')\n",
    "kmean.fit(df_aniso.loc[:, [\"x1\", \"x2\"]])\n",
    "df_aniso.loc[:, \"cluster\"] = kmean.labels_\n",
    "plot_point_clouds(data=df_aniso, \n",
    "                  feature_x=\"x1\", \n",
    "                  feature_y=\"x2\", \n",
    "                  feature_label=\"cluster\",\n",
    "                  title=\"Anisotropic distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-02T02:13:24.298120Z",
     "start_time": "2020-12-02T02:13:24.078344Z"
    }
   },
   "outputs": [],
   "source": [
    "kmean = KMeans(\n",
    "    n_clusters=3, init='k-means++', \n",
    "    n_init=10, max_iter=300, tol=0.0001, \n",
    "    verbose=0, random_state=13, \n",
    "    algorithm='auto')\n",
    "kmean.fit(df_uniform.loc[:, [\"x1\", \"x2\"]])\n",
    "df_uniform.loc[:, \"cluster\"] = kmean.labels_\n",
    "plot_point_clouds(data=df_uniform, \n",
    "                  feature_x=\"x1\", \n",
    "                  feature_y=\"x2\", \n",
    "                  feature_label=\"cluster\",\n",
    "                  title=\"Uniform distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question :** Après avoir optimisé manuellement les paramètres du k-means, dans quelles situations renvoie-t-il des clusters pertinents ? Dans quels cas est-ce un échec ? Pour quelle raison ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Réponse :**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'algorithme DBSCAN (Density-Based Spatial Clustering of Applications with Noise) fonctionne en deux temps :\n",
    "- Toutes les observations suffisamment proches sont connectées entre elles.\n",
    "- Les observations avec un nombre minimal de voisins connectés sont considérées comme des *core samples*, à partir desquelles les clusters sont étendues. **Toutes les observations suffisamment proche d'un *core sample* appartiennent au même cluster que celui-ci**. \n",
    "\n",
    "Documentation : https://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code :** Complétez les cellules pour le DBSCAN ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-02T02:13:31.285001Z",
     "start_time": "2020-12-02T02:13:31.122199Z"
    }
   },
   "outputs": [],
   "source": [
    "dbscan =  # TO COMPLETE \n",
    "dbscan.fit(df_circles.loc[:, [\"x1\", \"x2\"]])\n",
    "df_circles.loc[:, \"cluster\"] = # TO COMPLETE\n",
    "plot_point_clouds(data=df_circles, \n",
    "                  feature_x=\"x1\", \n",
    "                  feature_y=\"x2\", \n",
    "                  feature_label=\"cluster\",\n",
    "                  title=\"Circles distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-02T02:13:31.828456Z",
     "start_time": "2020-12-02T02:13:31.620922Z"
    }
   },
   "outputs": [],
   "source": [
    "dbscan = # TO COMPLETE\n",
    "dbscan.fit(df_blobs.loc[:, [\"x1\", \"x2\"]])\n",
    "df_blobs.loc[:, \"cluster\"] = # TO COMPLETE\n",
    "plot_point_clouds(data=df_blobs, \n",
    "                  feature_x=\"x1\", \n",
    "                  feature_y=\"x2\", \n",
    "                  feature_label=\"cluster\",\n",
    "                  title=\"Gaussians distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-02T02:13:32.318594Z",
     "start_time": "2020-12-02T02:13:32.139075Z"
    }
   },
   "outputs": [],
   "source": [
    "dbscan = # TO COMPLETE\n",
    "dbscan.fit(df_aniso.loc[:, [\"x1\", \"x2\"]])\n",
    "df_aniso.loc[:, \"cluster\"] = # TO COMPLETE\n",
    "plot_point_clouds(data=df_aniso, \n",
    "                  feature_x=\"x1\", \n",
    "                  feature_y=\"x2\", \n",
    "                  feature_label=\"cluster\",\n",
    "                  title=\"Anisotropic distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-02T02:13:32.961884Z",
     "start_time": "2020-12-02T02:13:32.772842Z"
    }
   },
   "outputs": [],
   "source": [
    "dbscan = # TO COMPLETE\n",
    "dbscan.fit(df_uniform.loc[:, [\"x1\", \"x2\"]])\n",
    "df_uniform.loc[:, \"cluster\"] = # TO COMPLETE\n",
    "plot_point_clouds(data=df_uniform, \n",
    "                  feature_x=\"x1\", \n",
    "                  feature_y=\"x2\", \n",
    "                  feature_label=\"cluster\",\n",
    "                  title=\"Uniform distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question :** Après avoir optimisé manuellement les paramètres du DBSCAN, dans quelles situations renvoie-t-il des clusters pertinents ? Dans quels cas est-ce un échec ? Pour quelle raison ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Réponse :** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectral clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le clustering spectral consiste à :\n",
    "- construire une **matrice d'affinité des observations** en appliquant un kernel ou un algorithme des k plus proches voisins\n",
    "- construire une **matrice laplacienne normalisée** à partir de la matrice d'affinité\n",
    "- projeter la matrice laplacienne dans un **espace de plus faible dimension en utilisant son spectre** (ses vecteurs propres)\n",
    "- **clusteriser** cet espace\n",
    "\n",
    "L'avantage de cette méthode est de pouvoir retrouver des clusters avec une structure non convexes. La construction de la matrice d'affinité permet également une grande flexibilité et de raisonner sur des graphes.\n",
    "\n",
    "Documentation : https://scikit-learn.org/stable/modules/generated/sklearn.cluster.SpectralClustering.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-02T02:13:35.209198Z",
     "start_time": "2020-12-02T02:13:34.545816Z"
    }
   },
   "outputs": [],
   "source": [
    "spectral = SpectralClustering(\n",
    "    n_clusters=3, random_state=13, \n",
    "    n_init=10, gamma=1.0, affinity='nearest_neighbors', n_neighbors=5)\n",
    "spectral.fit(df_circles.loc[:, [\"x1\", \"x2\"]])\n",
    "df_circles.loc[:, \"cluster\"] = spectral.labels_\n",
    "plot_point_clouds(data=df_circles, \n",
    "                  feature_x=\"x1\", \n",
    "                  feature_y=\"x2\", \n",
    "                  feature_label=\"cluster\",\n",
    "                  title=\"Circles distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-02T02:13:35.526948Z",
     "start_time": "2020-12-02T02:13:35.211412Z"
    }
   },
   "outputs": [],
   "source": [
    "spectral = SpectralClustering(\n",
    "    n_clusters=3, random_state=13, \n",
    "    n_init=10, gamma=1.0, affinity='nearest_neighbors', n_neighbors=5)\n",
    "spectral.fit(df_blobs.loc[:, [\"x1\", \"x2\"]])\n",
    "df_blobs.loc[:, \"cluster\"] = spectral.labels_\n",
    "plot_point_clouds(data=df_blobs, \n",
    "                  feature_x=\"x1\", \n",
    "                  feature_y=\"x2\", \n",
    "                  feature_label=\"cluster\",\n",
    "                  title=\"Gaussians distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-02T02:13:35.939833Z",
     "start_time": "2020-12-02T02:13:35.529405Z"
    }
   },
   "outputs": [],
   "source": [
    "spectral = SpectralClustering(\n",
    "    n_clusters=3, random_state=13, \n",
    "    n_init=10, gamma=1.0, affinity='nearest_neighbors', n_neighbors=5)\n",
    "spectral.fit(df_aniso.loc[:, [\"x1\", \"x2\"]])\n",
    "df_aniso.loc[:, \"cluster\"] = spectral.labels_\n",
    "plot_point_clouds(data=df_aniso, \n",
    "                  feature_x=\"x1\", \n",
    "                  feature_y=\"x2\", \n",
    "                  feature_label=\"cluster\",\n",
    "                  title=\"Anisotropic distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-02T02:20:58.269848Z",
     "start_time": "2020-12-02T02:20:58.176693Z"
    }
   },
   "outputs": [],
   "source": [
    "spectral = SpectralClustering(\n",
    "    n_clusters=3, random_state=13, \n",
    "    n_init=10, gamma=1.0, affinity='rbf', n_neighbors=5)\n",
    "spectral.fit(df_uniform.loc[:, [\"x1\", \"x2\"]])\n",
    "df_uniform.loc[:, \"cluster\"] = spectral.labels_\n",
    "plot_point_clouds(data=df_uniform, \n",
    "                  feature_x=\"x1\", \n",
    "                  feature_y=\"x2\", \n",
    "                  feature_label=\"cluster\",\n",
    "                  title=\"Uniform distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question :** Après avoir optimisé manuellement les paramètres du spectral clustering, dans quelles situations renvoie-t-il des clusters pertinents ? Dans quels cas est-ce un échec ? Pour quelle raison ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Réponse :** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian mixture model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le modèle de mélange gaussienne cherche à **optimiser les paramètres d'un nombre fini de gaussiennes** aux données. L'impémentation de scikit-learn utilise un algorithme Expectation-Maximization (EM) pour faire converger le modèle.\n",
    "\n",
    "Documentation : https://scikit-learn.org/stable/modules/generated/sklearn.mixture.GaussianMixture.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-02T02:13:37.561778Z",
     "start_time": "2020-12-02T02:13:37.391095Z"
    }
   },
   "outputs": [],
   "source": [
    "gmm = GaussianMixture(\n",
    "    n_components=3, max_iter=100, \n",
    "    n_init=1, init_params='kmeans', random_state=13)\n",
    "gmm.fit(df_circles.loc[:, [\"x1\", \"x2\"]])\n",
    "df_circles.loc[:, \"cluster\"] = gmm.predict(df_circles.loc[:, [\"x1\", \"x2\"]])\n",
    "plot_point_clouds(data=df_circles, \n",
    "                  feature_x=\"x1\", \n",
    "                  feature_y=\"x2\", \n",
    "                  feature_label=\"cluster\",\n",
    "                  title=\"Circles distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-02T02:13:37.872474Z",
     "start_time": "2020-12-02T02:13:37.669917Z"
    }
   },
   "outputs": [],
   "source": [
    "gmm = GaussianMixture(\n",
    "    n_components=3, max_iter=100, \n",
    "    n_init=1, init_params='kmeans', random_state=13)\n",
    "gmm.fit(df_blobs.loc[:, [\"x1\", \"x2\"]])\n",
    "df_blobs.loc[:, \"cluster\"] = gmm.predict(df_blobs.loc[:, [\"x1\", \"x2\"]])\n",
    "plot_point_clouds(data=df_blobs, \n",
    "                  feature_x=\"x1\", \n",
    "                  feature_y=\"x2\", \n",
    "                  feature_label=\"cluster\",\n",
    "                  title=\"Gaussians distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-02T02:13:38.275264Z",
     "start_time": "2020-12-02T02:13:38.077268Z"
    }
   },
   "outputs": [],
   "source": [
    "gmm = GaussianMixture(\n",
    "    n_components=3, max_iter=100, \n",
    "    n_init=1, init_params='kmeans', random_state=13)\n",
    "gmm.fit(df_aniso.loc[:, [\"x1\", \"x2\"]])\n",
    "df_aniso.loc[:, \"cluster\"] = gmm.predict(df_aniso.loc[:, [\"x1\", \"x2\"]])\n",
    "plot_point_clouds(data=df_aniso, \n",
    "                  feature_x=\"x1\", \n",
    "                  feature_y=\"x2\", \n",
    "                  feature_label=\"cluster\",\n",
    "                  title=\"Anisotropic distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-02T02:13:38.666912Z",
     "start_time": "2020-12-02T02:13:38.477825Z"
    }
   },
   "outputs": [],
   "source": [
    "gmm = GaussianMixture(\n",
    "    n_components=3, max_iter=100, \n",
    "    n_init=1, init_params='kmeans', random_state=13)\n",
    "gmm.fit(df_uniform.loc[:, [\"x1\", \"x2\"]])\n",
    "df_uniform.loc[:, \"cluster\"] = gmm.predict(df_uniform.loc[:, [\"x1\", \"x2\"]])\n",
    "plot_point_clouds(data=df_uniform, \n",
    "                  feature_x=\"x1\", \n",
    "                  feature_y=\"x2\", \n",
    "                  feature_label=\"cluster\",\n",
    "                  title=\"Uniform distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question :** Après avoir optimisé manuellement les paramètres de la mélange de gaussiennes, dans quelles situations renvoie-t-il des clusters pertinents ? Dans quels cas est-ce un échec ? Pour quelle raison ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Réponse :** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question :** Parmi ces 4 algorithmes de clustering, lequel se distingue des 3 autres au niveau de ses pre-requis ? Pourquoi ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Réponse :** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Evaluation des clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Silhouette scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le coefficient (ou score) de silhouette permet de **comparer les distances moyennes intra- et inter-cluster** :\n",
    "\n",
    "\\begin{align}\n",
    "\\text{score} = \\frac{b - a}{\\max(a, b)}\n",
    "\\end{align}\n",
    "\n",
    "avec $a$ la distance moyenne intra-cluster et $b$ la distance d'un point au cluster étranger le plus proche. Le score se calcule par observation (avec une valeur entre -1 et 1) puis la moyenne de ce score permet d'évaluer le clustering du nuage de point dans son ensemble.\n",
    "\n",
    "Documentation : https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html#sklearn.metrics.silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-02T02:13:42.165428Z",
     "start_time": "2020-12-02T02:13:41.897717Z"
    }
   },
   "outputs": [],
   "source": [
    "# clustering\n",
    "kmean = KMeans(\n",
    "    n_clusters=3, init='k-means++', \n",
    "    n_init=10, max_iter=300, tol=0.0001, \n",
    "    verbose=0, random_state=13, \n",
    "    algorithm='auto')\n",
    "kmean.fit(df_blobs.loc[:, [\"x1\", \"x2\"]])\n",
    "\n",
    "# update dataframe clusters\n",
    "df_blobs.loc[:, \"cluster\"] = kmean.labels_\n",
    "\n",
    "# compute silhouette score\n",
    "score = silhouette_score(\n",
    "    df_blobs.loc[:, [\"x1\", \"x2\"]], \n",
    "    labels=df_blobs.loc[:, \"cluster\"], \n",
    "    random_state=13)\n",
    "\n",
    "# plot\n",
    "plot_point_clouds(data=df_blobs, \n",
    "                  feature_x=\"x1\", \n",
    "                  feature_y=\"x2\", \n",
    "                  feature_label=\"cluster\",\n",
    "                  title=\"Silhouette score: {0:0.3f}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question :** Pour quel nombre de clusters recherchés le score de silhouette est-il le plus élevé ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Réponse :** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code :** En utilisant la distribution anisotrope, calculer le score de silhouette moyen avec les vrais clusters du nuage de point (et non ceux prédits par k-means)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-02T02:13:46.193433Z",
     "start_time": "2020-12-02T02:13:45.526488Z"
    }
   },
   "outputs": [],
   "source": [
    "# score ground truth\n",
    "score = # TO COMPLETE\n",
    "title = \"Ground truth | Silhouette score: {0:0.3f}\".format(score)\n",
    "plot_point_clouds(data=df_aniso, \n",
    "                  feature_x=\"x1\", \n",
    "                  feature_y=\"x2\", \n",
    "                  feature_label=\"label\",\n",
    "                  title=title)\n",
    "\n",
    "# score 2 clusters\n",
    "kmean = # TO COMPLETE\n",
    "df_aniso.loc[:, \"cluster\"] = # TO COMPLETE\n",
    "score = # TO COMPLETE\n",
    "title = \"Clusters: 2 | Silhouette score: {0:0.3f}\".format(score)\n",
    "plot_point_clouds(data=df_aniso, \n",
    "                  feature_x=\"x1\", \n",
    "                  feature_y=\"x2\", \n",
    "                  feature_label=\"cluster\",\n",
    "                  title=title)\n",
    "\n",
    "# score 3 clusters\n",
    "kmean = # TO COMPLETE\n",
    "df_aniso.loc[:, \"cluster\"] = # TO COMPLETE\n",
    "score = # TO COMPLETE\n",
    "title = \"Clusters: 3 | Silhouette score: {0:0.3f}\".format(score)\n",
    "plot_point_clouds(data=df_aniso, \n",
    "                  feature_x=\"x1\", \n",
    "                  feature_y=\"x2\", \n",
    "                  feature_label=\"cluster\",\n",
    "                  title=title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-02T01:16:59.965308Z",
     "start_time": "2020-12-02T01:16:59.960762Z"
    }
   },
   "source": [
    "**Question :** A votre avis, le score de silhouette est-il sensible à la géométrie des clusters (convexité, densité, etc.) ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Réponse :** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Silhouette plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En complément du score de silhouette, il est possible d'afficher le score de chaque observation et de **visualiser la *silhouette* des clusters**.\n",
    "\n",
    "Documentation : https://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_silhouette_analysis.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code :** Adaptez le code ci-dessous pour afficher le graphique de silhouette dans le cadre des données gaussiennes clusterisées avec un k-means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-02T02:13:50.371833Z",
     "start_time": "2020-12-02T02:13:47.817213Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get input values\n",
    "X = # TO COMPLETE\n",
    "\n",
    "# one silhouette plot for different numbers of clusters.\n",
    "for n_clusters in range(2, 7):\n",
    "    \n",
    "    # create a subplot with 1 row and 2 columns\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    fig.set_size_inches(18, 7)\n",
    "    \n",
    "    # demarcate silhouette plots of individual clusters by inserting blanck space\n",
    "    ax1.set_ylim([0, len(X) + (n_clusters + 1) * 10])\n",
    "\n",
    "    # K-means clustering\n",
    "    kmean = # TO COMPLETE\n",
    "    cluster_labels = # TO COMPLETE\n",
    "\n",
    "    # compute average silhouette score\n",
    "    score = silhouette_score(X, cluster_labels)\n",
    "\n",
    "    # compute silhouette scores for each sample\n",
    "    sample_silhouette_values = # TO COMPLETE\n",
    "\n",
    "    # plot silhouette scores for each sample\n",
    "    y_lower = 10\n",
    "    for i in range(n_clusters):\n",
    "        \n",
    "        # aggregate the silhouette scores for samples belonging to cluster i and sort them\n",
    "        ith_cluster_silhouette_values = sample_silhouette_values[cluster_labels == i]\n",
    "        ith_cluster_silhouette_values.sort()\n",
    "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "        y_upper = y_lower + size_cluster_i\n",
    "        color = cm.nipy_spectral(float(i) / n_clusters)\n",
    "        ax1.fill_betweenx(np.arange(y_lower, y_upper),\n",
    "                          0, ith_cluster_silhouette_values,\n",
    "                          facecolor=color, edgecolor=color, alpha=0.7)\n",
    "\n",
    "        # label the silhouette plots with their cluster numbers at the middle\n",
    "        ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "\n",
    "        # compute the new y_lower for next plot\n",
    "        y_lower = y_upper + 10  # 10 for the 0 samples\n",
    "\n",
    "    # axis labels and title\n",
    "    ax1.set_title(\"Average silhouette coefficient: {0:0.3f}\".format(score), fontsize=15)\n",
    "    ax1.set_xlabel(\"Silhouette coefficient values\", fontsize=15)\n",
    "    ax1.set_ylabel(\"Cluster label\", fontsize=15)\n",
    "\n",
    "    # draw a vertical line for average silhouette score of all the values\n",
    "    ax1.axvline(x=score, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "    # clear the yaxis labels / ticks\n",
    "    ax1.set_yticks([])  \n",
    "    ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "\n",
    "    # 2nd plot showing the actual clusters formed\n",
    "    colors = cm.nipy_spectral(cluster_labels.astype(float) / n_clusters)\n",
    "    ax2.scatter(X[:, 0], X[:, 1], \n",
    "                marker='o', s=30, alpha=0.8, c=colors, edgecolor='k')    \n",
    "    \n",
    "    # draw white circles at cluster centers\n",
    "    centers = # TO COMPLETE\n",
    "    ax2.scatter(centers[:, 0], centers[:, 1], marker='o',\n",
    "                c=\"white\", alpha=1, s=200, edgecolor='k')\n",
    "\n",
    "    for i, c in enumerate(centers):\n",
    "        ax2.scatter(c[0], c[1], marker='$%d$' % i, alpha=1,\n",
    "                    s=50, edgecolor='k')\n",
    "        \n",
    "    # axis labels and title\n",
    "    ax2.set_title(\"Number of clusters: {0}\".format(n_clusters), fontsize=15)\n",
    "    ax2.set_xlabel(\"X1\", fontsize=15)\n",
    "    ax2.set_ylabel(\"X2\", fontsize=15)\n",
    "\n",
    "    # main title\n",
    "    plt.suptitle((\"Silhouette analysis for K-means clustering on sample data \"\n",
    "                  \"with n_clusters = {0}\".format(n_clusters)),\n",
    "                 fontsize=20, fontweight='bold')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question :** Quels sont les éléments de ce graphique qui peuvent vous aider à prendre une décision sur un paramètre (ici le nombre de clusters à détecter) ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Réponse :** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjusted Rand Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'index ajusté Rand permet de **comparer un résultat de clustering avec les vrais clusters**. Pour chaque paire d'observations nous regardons si elles se situent dans le même cluster ou non, dans le clustering prédit et réel. L'index prend des valeurs entre 0 (clustering aléatoire) et 1 (clustering parfait).\n",
    "\n",
    "Documentation : https://scikit-learn.org/stable/modules/generated/sklearn.metrics.adjusted_rand_score.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code :** Calculez l'index ajusté Rand pour un clustering k-means sur les distributions gaussiennes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-02T02:13:53.745318Z",
     "start_time": "2020-12-02T02:13:53.521409Z"
    }
   },
   "outputs": [],
   "source": [
    "# clustering\n",
    "kmean = KMeans(\n",
    "    n_clusters=3, init='k-means++', \n",
    "    n_init=10, max_iter=300, tol=0.0001, \n",
    "    verbose=0, random_state=13, \n",
    "    algorithm='auto')\n",
    "kmean.fit(df_blobs.loc[:, [\"x1\", \"x2\"]])\n",
    "\n",
    "# update dataframe clusters\n",
    "df_blobs.loc[:, \"cluster\"] = kmean.labels_\n",
    "\n",
    "# compute Adjusted Rand Index\n",
    "ari = # TO COMPLETE\n",
    "\n",
    "# plot\n",
    "plot_point_clouds(data=df_blobs, \n",
    "                  feature_x=\"x1\", \n",
    "                  feature_y=\"x2\", \n",
    "                  feature_label=\"cluster\",\n",
    "                  title=\"Adjusted Rand Index: {0:0.3}\".format(ari))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Cas pratique (optionnel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code :** Maintenant essayez de maximiser l'index ajusté Rand sur les données réelles de pingouins.\n",
    "\n",
    "- N'oubliez pas que vous pouvez retirer les valeurs manquantes de votre base de données ou les imputer avec `sklearn.impute.SimpleImputer`.\n",
    "- Vous pouvez chercher l'ensemble de features le plus pertinent pour clusteriser les espèces de pingouins ou bien conserver l'ensemble des features et les projeter dans un espace de dimension réduit avec `sklearn.decomposition.PCA` (précédé par `sklearn.preprocessing.StandardScaler`).\n",
    "- Choisissez le bon algorithme de clustering d'après ce que l'on vient de voir sur les données simulées.\n",
    "- Optimiser les paramètres de cet algorithme en utilisant les coefficients et les graphiques de silhouette.\n",
    "- Afficher les clusters que vous prédisez pour être sûr de ne pas faire fausse route !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
